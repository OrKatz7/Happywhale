{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a0ed03-da1c-4e48-890e-940c5e44d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1802: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1828: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from utils import seed_torch\n",
    "from train import main\n",
    "import train_configs\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0647bd88-2e0e-4ba8-8255-d4c633a3fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/kaor/.conda/envs/openmmlab/bin/python -m pip install -U timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1953bf-9e25-447e-9cfd-2c1c9c40d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = train_configs.config16v4sampler.config\n",
    "# config2 = train_configs.config10.config\n",
    "seed_torch(config1.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff20cc2c-aba4-4cff-ac3a-fc529f12d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaor/.conda/envs/openmmlab/bin/python\n",
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n",
      "[GCC 9.4.0]\n",
      "sys.version_info(major=3, minor=7, micro=12, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e414aa6e-180a-4b3c-b4f1-1a48a43239e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from models.eff import get_model\n",
    "from runner import *\n",
    "from post_processing import *\n",
    "from datasets import *\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + '.pbz2', 'w') as f:\n",
    "        cPickle.dump(data, f)\n",
    "        \n",
    "def decompress_pickle(file):\n",
    "     data = bz2.BZ2File(file, 'rb')\n",
    "     data = cPickle.load(data)\n",
    "     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be61ad4-7b0b-4896-8e50-35215536ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config1.kfold_csv)\n",
    "test = pd.read_csv('../../whale/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5a8d55-ac2c-4492-aa48-0dc6c8742ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_fn_test(valid_loader, model, device,with_file_name = False):\n",
    "    model.eval()\n",
    "    emb = []\n",
    "    targets = []\n",
    "    start = end = time.time()\n",
    "    for step, batch in enumerate(tqdm(valid_loader)):\n",
    "        # measure data loading time\n",
    "        images = batch['image'].to(device)\n",
    "        if not with_file_name:\n",
    "            labels = batch['label'].to(device).long()\n",
    "            labels2 = batch['species'].to(device).long()\n",
    "        batch_size = images.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model.extract_feature(images).cpu().numpy() + model.extract_feature(images.flip(-1)).cpu().numpy()\n",
    "            emb.append(y_preds)\n",
    "            if not with_file_name:\n",
    "                targets.append(labels.cpu().numpy())\n",
    "            else:\n",
    "                targets.append(batch['file_name'])\n",
    "    emb = np.concatenate(emb)\n",
    "    targets = np.concatenate(targets)\n",
    "    \n",
    "    return emb,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ff17da-aff5-4845-a17f-db4b86842eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaor/whale_code/output/exp16v4sampler_fold0_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [10:16<00:00,  1.42it/s]\n",
      "100%|██████████| 1595/1595 [19:57<00:00,  1.33it/s]\n",
      "100%|██████████| 437/437 [00:00<00:00, 597.71it/s]\n"
     ]
    }
   ],
   "source": [
    "name_dict = {}\n",
    "for row in train[['individual_id','classes']].drop_duplicates().values:\n",
    "    name_dict[row[1]]=row[0]\n",
    "\n",
    "for config in [config1]:\n",
    "    valid_dataset = TrainDataset(train, config.data_root_path,transform=config.val_transforms,\n",
    "                                 crop_p=1.0,crop_csv_path=config.crop_csv_path,crop_backfin_csv_path=config.crop_backfin_csv_path,mode='test')\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                                  batch_size=32, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=4, \n",
    "                                  pin_memory=True, \n",
    "                                  drop_last=False)\n",
    "    test_dataset = TestDataset(test, config.data_root_path.replace(\"train_images\",\"test_images\"),transform=config.val_transforms,\n",
    "                               crop_p=1.0,crop_csv_path='/home/kaor/whale_code/yolo/test_bbox3.csv',\n",
    "                               crop_backfin_csv_path='/home/kaor/whale_code/yolo/test_bbox_backfin2.csv')\n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                                  batch_size=32, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=4, \n",
    "                                  pin_memory=True,drop_last=False)\n",
    "    for fold in range(5):\n",
    "        model_path = config.save_dir+f'{config.exp_name}_fold{fold}_best.pth'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        if os.path.exists(f\"{config.exp_name}_fold{fold}.csv\"):\n",
    "            continue\n",
    "        print(model_path)\n",
    "        model = eval(config.model['f_class'])(**config.model['args']).to(config.device)\n",
    "        model.load_state_dict(torch.load(model_path)['model'])\n",
    "        emb_test,targets_filename = emb_fn_test(test_loader, model, config.device,with_file_name = True)\n",
    "        emb_val,targets_val = emb_fn_test(valid_loader, model, config.device,with_file_name = False)\n",
    "        data = {'emb_val':emb_val,\"targets_val\":targets_val,\"emb_test\":emb_test,\"targets_filename\":targets_filename}\n",
    "        compressed_pickle(config.save_dir+f'{config.exp_name}_fold{fold}', data)\n",
    "        EMB_SIZE = 512\n",
    "        vals_blend = []\n",
    "        labels_blend = []\n",
    "        inds_blend = []\n",
    "        for i in range(1):    \n",
    "            vals, inds = get_topk_cossim_sub(emb_test[:,i*EMB_SIZE:(i+1)*EMB_SIZE], emb_val[:,i*EMB_SIZE:(i+1)*EMB_SIZE], k=1500)\n",
    "            vals = vals.data.cpu().numpy()\n",
    "            inds = inds.data.cpu().numpy()\n",
    "            labels = np.concatenate([targets_val[inds[:,i]].reshape(-1,1) for i in range(inds.shape[1])], axis=1)\n",
    "            vals_blend.append(vals)\n",
    "            labels_blend.append(labels)\n",
    "            inds_blend.append(inds)\n",
    "        df = []\n",
    "        for i,t in enumerate(targets_filename):\n",
    "            res = []\n",
    "            cc= labels_blend[0][i]\n",
    "            for c in cc:\n",
    "                tl = name_dict[c]\n",
    "                if tl not in res:\n",
    "                    res.append(tl)\n",
    "                    if 'new_individual' not in res:\n",
    "                        res.append('new_individual')\n",
    "                    if len(res)==5:\n",
    "                        break\n",
    "            df.append([t,\" \".join(res)])\n",
    "        pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}_fold{fold}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fefdf10-3a4c-41f0-b295-c2c0fdfedf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6693421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = vals_blend[0][:,0].mean()\n",
    "vals_blend[0][:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5da83f-7f0b-43bb-b268-75e3d21dfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i,t in enumerate(targets_filename):\n",
    "    res = []\n",
    "    cc= labels_blend[0][i]\n",
    "    dist = vals_blend[0][i]\n",
    "    for c,di in zip(cc,dist):\n",
    "        tl = name_dict[c]\n",
    "        if tl not in res:\n",
    "            res.append(tl)\n",
    "            if 'new_individual' not in res and di<th:\n",
    "                res.append('new_individual')\n",
    "            if len(res)==5:\n",
    "                break\n",
    "    df.append([t,\" \".join(res)])\n",
    "pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}_fold{fold}_th.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fc9f2-2a23-4f07-90d9-bbaa74d7f2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afda7dbb-4951-4687-b02a-d62bd4aaf5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 10 18:27:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 65%   55C    P2   117W / 350W |   7168MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     23054      C   ...envs/openmmlab/bin/python     7163MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35765f19-7d6f-4883-8fea-1428c971882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df,columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aaf71a5-f0f5-438b-af38-9b8078019c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread(\"/home/kaor/whale/test_images/0485e977ceedaf.jpg\")[1000:1200,1500:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05d2738-01ed-4e80-b2f5-d73d9d20657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d54f06b4-0ba7-4b4a-8628-e492a0c56be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMB_SIZE = 512\n",
    "# vals_blend = []\n",
    "# labels_blend = []\n",
    "# inds_blend = []\n",
    "# for i in range(1):    \n",
    "#     vals, inds = get_topk_cossim_sub(emb_test[:,i*EMB_SIZE:(i+1)*EMB_SIZE], emb_val[:,i*EMB_SIZE:(i+1)*EMB_SIZE], k=1500)\n",
    "#     vals = vals.data.cpu().numpy()\n",
    "#     inds = inds.data.cpu().numpy()\n",
    "#     labels = np.concatenate([targets_val[inds[:,i]].reshape(-1,1) for i in range(inds.shape[1])], axis=1)\n",
    "#     vals_blend.append(vals)\n",
    "#     labels_blend.append(labels)\n",
    "#     inds_blend.append(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b85e9e1-8123-4d5a-82ab-f3064310b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_dict = {}\n",
    "# for row in train[['individual_id','classes']].drop_duplicates().values:\n",
    "#     name_dict[row[1]]=row[0]\n",
    "# # name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae5db647-6e92-48ef-8b1d-a84a7abc30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = labels_blend[0][0]\n",
    "# if cc[0]!=cc[1] or cc[1]==cc[2]:\n",
    "#     print(cc[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca2d729-bb26-46fe-af42-95e04ea9b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = []\n",
    "# for i,t in enumerate(targets_filename):\n",
    "#     res = []\n",
    "#     cc= labels_blend[0][i]\n",
    "#     for c in cc:\n",
    "#         tl = name_dict[c]\n",
    "#         if tl not in res:\n",
    "#             res.append(tl)\n",
    "#             if 'new_individual' not in res:\n",
    "#                 res.append('new_individual')\n",
    "#             if len(res)==5:\n",
    "#                 break\n",
    "#     df.append([t,\" \".join(res)])\n",
    "# pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61d527a-9f26-4192-b136-ce107e77cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# neigh = NearestNeighbors(n_neighbors=500,metric='cosine')\n",
    "# neigh.fit(emb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a00e7bcf-f68a-423c-9cc6-0a0b58486caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(df,columns=test.columns)\n",
    "# # for row in df['predictions']:\n",
    "# #     if \"new\" in row:\n",
    "# #         print(row)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0e255d-d0db-4ed0-8601-29444f77550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in train['individual_id']:\n",
    "#     if \"new\" in row:\n",
    "#         print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mmlabv2)",
   "language": "python",
   "name": "openmmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

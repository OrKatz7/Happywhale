{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a0ed03-da1c-4e48-890e-940c5e44d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1802: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1828: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/home/kaor/.local/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from utils import seed_torch\n",
    "from train import main\n",
    "import train_configs\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1953bf-9e25-447e-9cfd-2c1c9c40d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = train_configs.config16.config\n",
    "# config2 = train_configs.config10.config\n",
    "\n",
    "seed_torch(config1.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff20cc2c-aba4-4cff-ac3a-fc529f12d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaor/.conda/envs/openmmlab/bin/python\n",
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n",
      "[GCC 9.4.0]\n",
      "sys.version_info(major=3, minor=7, micro=12, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e414aa6e-180a-4b3c-b4f1-1a48a43239e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from models.eff import get_model\n",
    "from runner import *\n",
    "from post_processing import *\n",
    "from datasets import *\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + '.pbz2', 'w') as f:\n",
    "        cPickle.dump(data, f)\n",
    "        \n",
    "def decompress_pickle(file):\n",
    "     data = bz2.BZ2File(file, 'rb')\n",
    "     data = cPickle.load(data)\n",
    "     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be61ad4-7b0b-4896-8e50-35215536ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config1.kfold_csv)\n",
    "test = pd.read_csv('../../whale/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5a8d55-ac2c-4492-aa48-0dc6c8742ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_fn_test(valid_loader, model, device,with_file_name = False):\n",
    "    model.eval()\n",
    "    emb = []\n",
    "    targets = []\n",
    "    start = end = time.time()\n",
    "    for step, batch in enumerate(tqdm(valid_loader)):\n",
    "        # measure data loading time\n",
    "        images = batch['image'].to(device)\n",
    "        if not with_file_name:\n",
    "            labels = batch['label'].to(device).long()\n",
    "            labels2 = batch['species'].to(device).long()\n",
    "        batch_size = images.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model.extract_feature(images).cpu().numpy()\n",
    "            emb.append(y_preds)\n",
    "            if not with_file_name:\n",
    "                targets.append(labels.cpu().numpy())\n",
    "            else:\n",
    "                targets.append(batch['file_name'])\n",
    "    emb = np.concatenate(emb)\n",
    "    targets = np.concatenate(targets)\n",
    "    \n",
    "    return emb,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ff17da-aff5-4845-a17f-db4b86842eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaor/whale_code/output/exp16_fold0_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [10:44<00:00,  1.36it/s]\n",
      " 77%|███████▋  | 1232/1595 [14:34<04:12,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaor/whale/train_images//67f849396b6aaf.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1595/1595 [18:46<00:00,  1.42it/s]\n",
      "100%|██████████| 437/437 [00:00<00:00, 447.84it/s]\n"
     ]
    }
   ],
   "source": [
    "name_dict = {}\n",
    "for row in train[['individual_id','classes']].drop_duplicates().values:\n",
    "    name_dict[row[1]]=row[0]\n",
    "\n",
    "for config in [config1]:\n",
    "    valid_dataset = TrainDataset(train, config.data_root_path,transform=config.val_transforms,\n",
    "                                 crop_p=1.0,crop_csv_path=config.crop_csv_path,crop_backfin_csv_path=config.crop_backfin_csv_path,mode='test')\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                                  batch_size=32, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=4, \n",
    "                                  pin_memory=True, \n",
    "                                  drop_last=False)\n",
    "    test_dataset = TestDataset(test, config.data_root_path.replace(\"train_images\",\"test_images\"),transform=config.val_transforms,\n",
    "                               crop_p=1.0,crop_csv_path='/home/kaor/whale_code/yolo/test_bbox.csv',\n",
    "                               crop_backfin_csv_path='/home/kaor/whale_code/yolo/test_bbox_backfin.csv')\n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                                  batch_size=32, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=4, \n",
    "                                  pin_memory=True,drop_last=False)\n",
    "    for fold in range(5):\n",
    "        model_path = config.save_dir+f'{config.exp_name}_fold{fold}_best.pth'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        if os.path.exists(f\"{config.exp_name}_fold{fold}.csv\"):\n",
    "            continue\n",
    "        print(model_path)\n",
    "        model = eval(config.model['f_class'])(**config.model['args']).to(config.device)\n",
    "        model.load_state_dict(torch.load(model_path)['model'])\n",
    "        emb_test,targets_filename = emb_fn_test(test_loader, model, config.device,with_file_name = True)\n",
    "        emb_val,targets_val = emb_fn_test(valid_loader, model, config.device,with_file_name = False)\n",
    "        data = {'emb_val':emb_val,\"targets_val\":targets_val,\"emb_test\":emb_test,\"targets_filename\":targets_filename}\n",
    "        compressed_pickle(config.save_dir+f'{config.exp_name}_fold{fold}', data)\n",
    "        EMB_SIZE = 512\n",
    "        vals_blend = []\n",
    "        labels_blend = []\n",
    "        inds_blend = []\n",
    "        for i in range(1):    \n",
    "            vals, inds = get_topk_cossim_sub(emb_test[:,i*EMB_SIZE:(i+1)*EMB_SIZE], emb_val[:,i*EMB_SIZE:(i+1)*EMB_SIZE], k=1500)\n",
    "            vals = vals.data.cpu().numpy()\n",
    "            inds = inds.data.cpu().numpy()\n",
    "            labels = np.concatenate([targets_val[inds[:,i]].reshape(-1,1) for i in range(inds.shape[1])], axis=1)\n",
    "            vals_blend.append(vals)\n",
    "            labels_blend.append(labels)\n",
    "            inds_blend.append(inds)\n",
    "        df = []\n",
    "        for i,t in enumerate(targets_filename):\n",
    "            res = []\n",
    "            cc= labels_blend[0][i]\n",
    "            for c in cc:\n",
    "                tl = name_dict[c]\n",
    "                if tl not in res:\n",
    "                    res.append(tl)\n",
    "                    if 'new_individual' not in res:\n",
    "                        res.append('new_individual')\n",
    "                    if len(res)==5:\n",
    "                        break\n",
    "            df.append([t,\" \".join(res)])\n",
    "        pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}_fold{fold}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fefdf10-3a4c-41f0-b295-c2c0fdfedf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28598335"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# th = vals_blend[0][:,0].mean()\n",
    "# vals_blend[0][:,0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b5da83f-7f0b-43bb-b268-75e3d21dfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = []\n",
    "# for i,t in enumerate(targets_filename):\n",
    "#     res = []\n",
    "#     cc= labels_blend[0][i]\n",
    "#     dist = vals_blend[0][i]\n",
    "#     for c,di in zip(cc,dist):\n",
    "#         tl = name_dict[c]\n",
    "#         if tl not in res:\n",
    "#             res.append(tl)\n",
    "#             if 'new_individual' not in res and di<(th-.1):\n",
    "#                 res.append('new_individual')\n",
    "#             if len(res)==5:\n",
    "#                 break\n",
    "#     df.append([t,\" \".join(res)])\n",
    "# pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}_fold{fold}_th.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35765f19-7d6f-4883-8fea-1428c971882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000110707af0ba.jpg</td>\n",
       "      <td>fbe2b15b5481 528e2b621c73 new_individual 0a870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006287ec424cb.jpg</td>\n",
       "      <td>1424c7fec826 new_individual c3b7d902e73c f0efb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000809ecb2ccad.jpg</td>\n",
       "      <td>1ce3ba6a3c29 new_individual b91c12ffc2b0 c0fd9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00098d1376dab2.jpg</td>\n",
       "      <td>c4274d90be60 new_individual 43946ac5a865 3d22c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000b8d89c738bd.jpg</td>\n",
       "      <td>cf500d3874bc new_individual bcc45b6870e5 83533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>fff6ff1989b5cd.jpg</td>\n",
       "      <td>734573d54bef new_individual 843297d1983b ec0aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27952</th>\n",
       "      <td>fff8fd932b42cb.jpg</td>\n",
       "      <td>839bd24faf23 new_individual 4e376cb4fd38 53954...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27953</th>\n",
       "      <td>fff96371332c16.jpg</td>\n",
       "      <td>2fad3a13934d new_individual fd983ada9fe2 23fa4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27954</th>\n",
       "      <td>fffc1c4d3eabc7.jpg</td>\n",
       "      <td>d85f2d5186cb new_individual a8fe10f7b3e0 e7f9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27955</th>\n",
       "      <td>fffc50be10c175.jpg</td>\n",
       "      <td>32a8f92d7809 new_individual 9b70331d7387 4587a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image                                        predictions\n",
       "0      000110707af0ba.jpg  fbe2b15b5481 528e2b621c73 new_individual 0a870...\n",
       "1      0006287ec424cb.jpg  1424c7fec826 new_individual c3b7d902e73c f0efb...\n",
       "2      000809ecb2ccad.jpg  1ce3ba6a3c29 new_individual b91c12ffc2b0 c0fd9...\n",
       "3      00098d1376dab2.jpg  c4274d90be60 new_individual 43946ac5a865 3d22c...\n",
       "4      000b8d89c738bd.jpg  cf500d3874bc new_individual bcc45b6870e5 83533...\n",
       "...                   ...                                                ...\n",
       "27951  fff6ff1989b5cd.jpg  734573d54bef new_individual 843297d1983b ec0aa...\n",
       "27952  fff8fd932b42cb.jpg  839bd24faf23 new_individual 4e376cb4fd38 53954...\n",
       "27953  fff96371332c16.jpg  2fad3a13934d new_individual fd983ada9fe2 23fa4...\n",
       "27954  fffc1c4d3eabc7.jpg  d85f2d5186cb new_individual a8fe10f7b3e0 e7f9e...\n",
       "27955  fffc50be10c175.jpg  32a8f92d7809 new_individual 9b70331d7387 4587a...\n",
       "\n",
       "[27956 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(df,columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf71a5-f0f5-438b-af38-9b8078019c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(plt.imread(\"/home/kaor/whale/test_images/0485e977ceedaf.jpg\")[1000:1200,1500:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d2738-01ed-4e80-b2f5-d73d9d20657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f06b4-0ba7-4b4a-8628-e492a0c56be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMB_SIZE = 512\n",
    "# vals_blend = []\n",
    "# labels_blend = []\n",
    "# inds_blend = []\n",
    "# for i in range(1):    \n",
    "#     vals, inds = get_topk_cossim_sub(emb_test[:,i*EMB_SIZE:(i+1)*EMB_SIZE], emb_val[:,i*EMB_SIZE:(i+1)*EMB_SIZE], k=1500)\n",
    "#     vals = vals.data.cpu().numpy()\n",
    "#     inds = inds.data.cpu().numpy()\n",
    "#     labels = np.concatenate([targets_val[inds[:,i]].reshape(-1,1) for i in range(inds.shape[1])], axis=1)\n",
    "#     vals_blend.append(vals)\n",
    "#     labels_blend.append(labels)\n",
    "#     inds_blend.append(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85e9e1-8123-4d5a-82ab-f3064310b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_dict = {}\n",
    "# for row in train[['individual_id','classes']].drop_duplicates().values:\n",
    "#     name_dict[row[1]]=row[0]\n",
    "# # name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5db647-6e92-48ef-8b1d-a84a7abc30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = labels_blend[0][0]\n",
    "# if cc[0]!=cc[1] or cc[1]==cc[2]:\n",
    "#     print(cc[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2d729-bb26-46fe-af42-95e04ea9b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = []\n",
    "# for i,t in enumerate(targets_filename):\n",
    "#     res = []\n",
    "#     cc= labels_blend[0][i]\n",
    "#     for c in cc:\n",
    "#         tl = name_dict[c]\n",
    "#         if tl not in res:\n",
    "#             res.append(tl)\n",
    "#             if 'new_individual' not in res:\n",
    "#                 res.append('new_individual')\n",
    "#             if len(res)==5:\n",
    "#                 break\n",
    "#     df.append([t,\" \".join(res)])\n",
    "# pd.DataFrame(df,columns=test.columns).to_csv(f\"{config.exp_name}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d527a-9f26-4192-b136-ce107e77cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# neigh = NearestNeighbors(n_neighbors=500,metric='cosine')\n",
    "# neigh.fit(emb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e7bcf-f68a-423c-9cc6-0a0b58486caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(df,columns=test.columns)\n",
    "# # for row in df['predictions']:\n",
    "# #     if \"new\" in row:\n",
    "# #         print(row)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e255d-d0db-4ed0-8601-29444f77550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in train['individual_id']:\n",
    "#     if \"new\" in row:\n",
    "#         print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mmlab)",
   "language": "python",
   "name": "mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
